# ğŸ³ ğŸ› ï¸ ğŸš€ Airflow Products ETL Pipeline

<<<<<<< HEAD
A containerized ETL pipeline using **Python, Pandas, Postgres, and Airflow**. 
=======
A containerized ETL pipeline using **Python, Pandas, Postgres, and Airflow**.
>>>>>>> ae399e8 (Clean repo: remove logs and pgdata, update .gitignore)

The pipeline:  

1ï¸âƒ£ Extracts product data from CSV  

2ï¸âƒ£ Filters products with price > 100  

3ï¸âƒ£ Cleans data (removes commas)  

4ï¸âƒ£ Loads filtered data into Postgres  

5ï¸âƒ£ Prints summary metrics and product names  

---

## ğŸ“‚ Project Structure
<<<<<<< HEAD
=======

>>>>>>> ae399e8 (Clean repo: remove logs and pgdata, update .gitignore)
```
airflow-products-project/
â”‚
â”œâ”€ dags/
â”‚ â””â”€ products_etl_dag.py # Airflow DAG defining the ETL workflow
â”‚
â”œâ”€ data/
â”‚ â””â”€ products.csv # Sample product dataset
â”‚
â”œâ”€ docker-compose.yml # Docker Compose setup for Airflow + Postgres
â”‚
â”œâ”€ README.md # This file
â””â”€ requirements.txt # Python dependencies
```

---

## ğŸ”§ Key Features

- **ETL Workflow**: Extract â†’ Transform â†’ Load  
- **Data Cleaning**: Strips trailing commas in product names & categories  
- **PostgreSQL Integration**: Saves filtered results to `products_filtered` table  
- **Airflow DAG**: Orchestrates daily ETL tasks  
- **Logging & Reporting**: Prints average price & item names  
- **Optional Email Notifications**: Alerts on task success/failure  

---

## ğŸ“Š Airflow DAG Overview

**DAG Tasks:**

| Task ID   | Description |
|----------|-------------|
| `extract`  | Read CSV into Pandas DataFrame |
| `transform`| Filter products with price > 100 & clean strings |
| `load`     | Save filtered data to Postgres & print summary |

---

## ğŸ³ Running Locally (Docker)

1. Start Containers:

```bash
docker compose up -d
```

1. Access Airflow UI:

```bash
"http://localhost:8080"
```

1. Start the scheduler in another terminal:

```bash
docker exec -it <airflow_container_name> airflow scheduler
```

1. Trigger DAG manually in UI ('play' button) or wait for daily run:

2. Verify Postgres tables:

```bash
docker exec -it <airflow_container_name> psql -U airflow -d airflow
```

<<<<<<< HEAD

=======
>>>>>>> ae399e8 (Clean repo: remove logs and pgdata, update .gitignore)
**SQL Commands inside psql**

Show all rows:

```sql
SELECT * FROM products_filtered;
```
Show metrics (average price over 100):

<<<<<<< HEAD
```sql 
`SELECT * FROM products_metrics;`
```

=======
Show metrics (average price over 100):

```sql
`SELECT * FROM products_metrics;`
```
>>>>>>> ae399e8 (Clean repo: remove logs and pgdata, update .gitignore)

**Screenshots:**

![Airflow DAG Screenshot](./images/1.successful_connection_to_airflow_ui_and_pipeline_run.png)

<<<<<<< HEAD
<br> 

![Postgres Output Screenshot](./images/2.successful_airflow_psql_outputs.png)



=======
<br>

![Postgres Output Screenshot](./images/2.successful_airflow_psql_outputs.png)
>>>>>>> ae399e8 (Clean repo: remove logs and pgdata, update .gitignore)
